{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c66fa18-fe6b-44b7-9a66-b2833231aa21",
   "metadata": {},
   "source": [
    "# Respiratory Disease Classification Model\n",
    "## 1. Data Gathering\n",
    "For this activity, a dataset has been provided split between three classes: Covid; Viral Pneumonia, and Normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa613b3-ab60-44cd-b244-02b712006f85",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Data\n",
    "For data preprocessing, tensorflow's built-in *preprocess input* will be used, as it is the most recent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71dae5dc-147b-42f9-9fd0-aae42d4d96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential                                                                     #used to define the model type.\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout     #used for defining each layer of the model\n",
    "from tensorflow.keras.optimizers import Adam                                                                       #used for defining what optimizer the model will use\n",
    "from tensorflow.keras.metrics import categorical_crossentropy                                                      #used for defining what metrics the model will use\n",
    "from sklearn.metrics import confusion_matrix                                                                       #used for model evaluation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator                                                #used for importing the data from the dataset\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint                                              #implemented for model training\n",
    "import matplotlib.pyplot as plt                                                                                    #used for plotting the confusion matrix earlier.\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "079e71b8-14a7-484b-85c4-beb252a17922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the directories of every image.\n",
    "train_dir = \"C:\\\\Users\\\\Dingus-Elite\\\\Desktop\\\\lung_dataset\\\\train\"\n",
    "test_dir = \"C:\\\\Users\\\\Dingus-Elite\\\\Desktop\\\\lung_dataset\\\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4fdd100d-99f8-44f5-9d20-3382df2734ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 249 images belonging to 3 classes.\n",
      "Found 65 images belonging to 3 classes.\n",
      "Found 10 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#Uses the imported ImageDataGenerator to preprocess every image\n",
    "#image size is set to 750x750.\n",
    "#Three classes are defined: the Covid, Viral Pneumonia and Normal.\n",
    "#Every vatch, 10 imaages will be handled.\n",
    "#for the valid_batch, I created a subfolder and moved the images there so the ImageDataGenerator works as intended.\n",
    "\n",
    "train_batch = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_dir, target_size=(224,224), classes=['Viral Pneumonia', 'Normal', 'Covid'], batch_size=10)\n",
    "test_batch = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_dir, target_size=(224,224), classes=['Viral Pneumonia', 'Normal', 'Covid'], batch_size=10)\n",
    "valid_batch = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(\"C:\\\\Users\\\\Dingus-Elite\\\\Desktop\\\\lung_dataset\\\\validation\", target_size=(224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7201e8-ca18-4734-b582-fbba61d0a088",
   "metadata": {},
   "source": [
    "## 3. Choosing a Model\n",
    "As part of the constraints, I'm assigned to using Conv2D as the basis for my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "289e04d0-71a7-4ec7-bada-ba91a16fb137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding = 'same', input_shape=(224,224,3)))          #Defining the 2D Convolution of the model, size is at 750x750\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))                                                                        #Used to reduce the image's size\n",
    "model.add(Dropout(0.2))                                                                                                  #Added to prevent overfitting\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(2, 2), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "model.add(Flatten())                                                                                                     #Falttens the multidimensional output of the previous\n",
    "                                                                                                                         #to 1D.\n",
    "model.add(Dense(units=3, activation='softmax'))                                                                          #Units are set to 3 as there are three categories\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])               #compiles the model with categorical crossentropy for the loss\n",
    "                                                                                                                         #Adam for optimizer with a learning rate of 0.0001, and 'accuracy' for metrics  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad0eff8-6265-47d7-9908-762082fa91bd",
   "metadata": {},
   "source": [
    "## 4. Training\n",
    "The prepared datasets earlier are fit into the model; the model is then trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "264d6e86-9c4e-46fe-9bcc-b3b97424f436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24/24 [==============================] - 11s 436ms/step - loss: 44.8462 - accuracy: 0.5188 - val_loss: 4.5861 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 10s 430ms/step - loss: 8.0125 - accuracy: 0.8159 - val_loss: 4.3649 - val_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 11s 432ms/step - loss: 4.2186 - accuracy: 0.8577 - val_loss: 5.3353 - val_accuracy: 0.7167\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 11s 438ms/step - loss: 1.7663 - accuracy: 0.9079 - val_loss: 1.5141 - val_accuracy: 0.8333\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 11s 432ms/step - loss: 2.1071 - accuracy: 0.9038 - val_loss: 0.9054 - val_accuracy: 0.9000\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 10s 420ms/step - loss: 3.0449 - accuracy: 0.8452 - val_loss: 5.0462 - val_accuracy: 0.7000\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 10s 403ms/step - loss: 1.5896 - accuracy: 0.8954 - val_loss: 1.2630 - val_accuracy: 0.9000\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 10s 429ms/step - loss: 0.6949 - accuracy: 0.9623 - val_loss: 1.3055 - val_accuracy: 0.9167\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 10s 417ms/step - loss: 1.0817 - accuracy: 0.9498 - val_loss: 1.5472 - val_accuracy: 0.8333\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 10s 408ms/step - loss: 0.9629 - accuracy: 0.9498 - val_loss: 1.1839 - val_accuracy: 0.9333\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 10s 416ms/step - loss: 0.9497 - accuracy: 0.9331 - val_loss: 1.5896 - val_accuracy: 0.8500\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 10s 408ms/step - loss: 0.4855 - accuracy: 0.9540 - val_loss: 1.6231 - val_accuracy: 0.8667\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 11s 442ms/step - loss: 0.1233 - accuracy: 0.9791 - val_loss: 1.6569 - val_accuracy: 0.8667\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 10s 414ms/step - loss: 0.7362 - accuracy: 0.9498 - val_loss: 1.2135 - val_accuracy: 0.8833\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 10s 416ms/step - loss: 0.3960 - accuracy: 0.9582 - val_loss: 1.2218 - val_accuracy: 0.9000\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 11s 446ms/step - loss: 0.0535 - accuracy: 0.9874 - val_loss: 1.6371 - val_accuracy: 0.8667\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 10s 416ms/step - loss: 0.1601 - accuracy: 0.9749 - val_loss: 1.4457 - val_accuracy: 0.8667\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 10s 414ms/step - loss: 0.0811 - accuracy: 0.9958 - val_loss: 1.5099 - val_accuracy: 0.9000\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 10s 413ms/step - loss: 0.1139 - accuracy: 0.9791 - val_loss: 2.1228 - val_accuracy: 0.8667\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 10s 418ms/step - loss: 0.1936 - accuracy: 0.9874 - val_loss: 1.6162 - val_accuracy: 0.8833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb87055220>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10                                                                                                         #Since the batches earlier is set at 10, batch_size will be also 10.\n",
    "model.fit(                                                                                                               #fitting the training data into the model.\n",
    "    x = train_batch,                                                                                                     #For this, the test_batch will be used as the validation data.\n",
    "    steps_per_epoch=train_batch.samples // batch_size, \n",
    "    epochs=20, \n",
    "    validation_data=test_batch, \n",
    "    validation_steps=test_batch.samples // batch_size,\n",
    "    verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ca315-87e1-4064-bd22-f8454646cd33",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "To evaluate my model, I used .evaluate function to see how it performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "011a6523-4cd6-45c7-98ea-b10bf0d93e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 154ms/step - loss: 1.5812 - accuracy: 0.8769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8769230842590332"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, val = model.evaluate(test_batch)\n",
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb550b9-ae73-47eb-9ab2-22489a38320a",
   "metadata": {},
   "source": [
    "## 6. Model Tuning\n",
    "Several parameters were modified throughout the duration of the test:\n",
    "- Added an additional Conv2D and MaxPooling layer. \n",
    "- Added droupout layers\n",
    "- Adjusted the kernel size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4d7dca-8afb-495f-ba7c-026310048faf",
   "metadata": {},
   "source": [
    "## 7. Prediction\n",
    "We then ask the model to predict the valid_data defined earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8572621d-4719-4155-85ca-e24de5824505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 323ms/step\n"
     ]
    }
   ],
   "source": [
    "acquired_values = model.predict(valid_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "60184098-a97f-4262-8a05-1c77ff858b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acquired_values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "43d4bff8-041d-4bb9-a77b-3df64b983ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N', 'Indeterminate', 'N', 'C', 'Indeterminate', 'N', 'V', 'C', 'V', 'V']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = []\n",
    "for i in range(0,10):\n",
    "    if acquired_values[i][0] == 1:\n",
    "        prediction.append(\"C\")\n",
    "    elif acquired_values[i][1] == 1:\n",
    "        prediction.append(\"V\")\n",
    "    elif acquired_values[i][2] == 1:\n",
    "         prediction.append(\"N\")\n",
    "    else:\n",
    "         prediction.append(\"Indeterminate\")\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2d04c9f7-9659-4e14-9467-43e5bf8d8df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'pic1', 'pic2', 'pic3', 'pic4', 'pic5', 'pic6', 'pic7', 'pic8', 'pic9', 'pic10']\n"
     ]
    }
   ],
   "source": [
    "picnos = [\"\"]\n",
    "for i in range(1,11):\n",
    "    picnos.append(\"pic\" + str(i))\n",
    "print(picnos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8a251b94-6349-4f9e-a390-6e3ab2ce92e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test_out = pd.DataFrame(picnos, columns=[\"\"]).to_csv(\"C:\\\\Users\\\\Dingus-Elite\\\\Desktop\\\\billones_cnn_output_ex.csv\")\n",
    "prediction_test_out = pd.DataFrame(prediction, columns=['diagnosis']).to_csv(\"C:\\\\Users\\\\Dingus-Elite\\\\Desktop\\\\billones_cnn_output_ex.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbdd2dd1-2922-42ab-953d-0198bf05bda6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstock_model.sav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mdump(model, \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10882a0-323d-41c4-8496-39b5df9439ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

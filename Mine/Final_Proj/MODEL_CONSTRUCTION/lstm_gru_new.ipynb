{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5acffef1-5e3e-449b-a55c-467bbed8187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pandas as pd                                                   \n",
    "from tensorflow.keras.models import Sequential, Model                        \n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, GRU, RepeatVector, TimeDistributed, Input               \n",
    "from sklearn.preprocessing import MinMaxScaler                        \n",
    "import numpy as np                                                    \n",
    "import matplotlib.pyplot as plt                                        \n",
    "import pickle\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8b732a-5100-45a9-a60b-1acc9fcd7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "GV = pd.read_csv(\"PPI_GV.csv\")\n",
    "\n",
    "Material_comp = pd.DataFrame()\n",
    "\n",
    "GV = GV.drop([\"DATE\"], axis = 1) \n",
    "GV = GV.iloc[::-1]\n",
    "GV = GV.iloc[:393]\n",
    "GV = GV.iloc[::-1]\n",
    "GV = GV.reset_index(drop=True) \n",
    "\n",
    "CB = pd.read_csv(\"PPI_CB.csv\")\n",
    "CB = CB.drop([\"DATE\"], axis = 1) \n",
    "CB = CB.iloc[::-1]\n",
    "CB = CB.iloc[:393]\n",
    "CB = CB.iloc[::-1]\n",
    "CB = CB.reset_index(drop=True) \n",
    "\n",
    "METAL = pd.read_csv(\"PPI_METAL.csv\")\n",
    "METAL = METAL.drop([\"DATE\"], axis = 1) \n",
    "METAL = METAL.iloc[::-1]\n",
    "METAL = METAL.iloc[:393]\n",
    "METAL = METAL.iloc[::-1]\n",
    "METAL = METAL.reset_index(drop=True) \n",
    "\n",
    "CNC = pd.read_csv(\"PPI_CNC.csv\")\n",
    "CNC = CNC.drop([\"DATE\"], axis = 1) \n",
    "CNC = CNC.iloc[::-1]\n",
    "CNC = CNC.iloc[:393]\n",
    "CNC = CNC.iloc[::-1]\n",
    "CNC = CNC.reset_index(drop=True) \n",
    "\n",
    "PL = pd.read_csv(\"PPI_PL.csv\")\n",
    "PL = PL.drop([\"DATE\"], axis = 1) \n",
    "PL = PL.iloc[::-1]\n",
    "PL = PL.iloc[:393]\n",
    "PL = PL.iloc[::-1]\n",
    "PL = PL.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7bc35b9-4fd9-4f10-b355-daf79f08dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Material_comp[\"Gravel\"] = GV\n",
    "Material_comp[\"Conc_Brick\"] = CB\n",
    "Material_comp[\"Metals\"] = METAL\n",
    "Material_comp[\"Concrete_Mix\"] = CNC\n",
    "Material_comp[\"Plywood\"] = PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1d064b0-89a8-46ca-bd6d-e6dccde182a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Material_comp.iloc[:354]\n",
    "val = Material_comp.iloc[:354]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f474a4be-2805-49e5-a397-95f7a8e5a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled = scaler.fit_transform(Material_comp.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3673733-db7d-4931-8295-d249208f86ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = []\n",
    "trainY = []\n",
    "\n",
    "n_future = 1   \n",
    "n_past = 14  \n",
    "\n",
    "for i in range(n_past, len(scaled) - n_future +1):\n",
    "    trainX.append(scaled[i - n_past:i, 0:train.shape[1]])\n",
    "    trainY.append(scaled[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "trainX, trainY = np.array(trainX,dtype=float), np.array(trainY,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b98efc50-45b7-4fa3-9bb8-08eebcb637d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45073bf4-68fb-4f12-936b-0c5f24613e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 14, 64)            17920     \n",
      "                                                                 \n",
      " gru_18 (GRU)                (None, 14, 64)            24960     \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 14, 128)           98816     \n",
      "                                                                 \n",
      " gru_19 (GRU)                (None, 14, 128)           99072     \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 14, 64)            49408     \n",
      "                                                                 \n",
      " gru_20 (GRU)                (None, 64)                24960     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 315,461\n",
      "Trainable params: 315,461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(GRU(64, activation='relu', return_sequences=True, recurrent_dropout=0.2))\n",
    "model.add(LSTM(128, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(GRU(128, activation='relu', return_sequences=True, recurrent_dropout=0.2))\n",
    "model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(GRU(64, activation='relu', return_sequences=False, recurrent_dropout=0.2))\n",
    "model.add(Dense(trainX.shape[2]))\n",
    "model.compile(optimizer='adam', loss=['mse','mape'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75cf4ed5-ebf6-44c9-a703-04962c34d374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22/22 [==============================] - 9s 80ms/step - loss: 0.0761 - val_loss: 0.0271\n",
      "Epoch 2/50\n",
      "22/22 [==============================] - 1s 47ms/step - loss: 0.0059 - val_loss: 0.0540\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0017 - val_loss: 0.0353\n",
      "Epoch 4/50\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 7.0420e-04 - val_loss: 0.0048\n",
      "Epoch 5/50\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 2.9072e-04 - val_loss: 0.0040\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - 1s 46ms/step - loss: 2.2318e-04 - val_loss: 0.0040\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - 1s 43ms/step - loss: 1.9167e-04 - val_loss: 0.0031\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - 1s 46ms/step - loss: 1.9634e-04 - val_loss: 0.0038\n",
      "Epoch 9/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 2.4498e-04 - val_loss: 3.6173e-04\n",
      "Epoch 10/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 2.1922e-04 - val_loss: 6.6885e-04\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 1.2660e-04 - val_loss: 0.0018\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - 1s 42ms/step - loss: 1.6731e-04 - val_loss: 4.3212e-04\n",
      "Epoch 13/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 1.2581e-04 - val_loss: 2.1814e-04\n",
      "Epoch 14/50\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 1.1762e-04 - val_loss: 2.1177e-04\n",
      "Epoch 15/50\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 2.1804e-04 - val_loss: 0.0015\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 2.2177e-04 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 2.9720e-04 - val_loss: 1.7832e-04\n",
      "Epoch 18/50\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 8.9818e-05 - val_loss: 1.8291e-04\n",
      "Epoch 19/50\n",
      "22/22 [==============================] - 1s 42ms/step - loss: 9.1279e-05 - val_loss: 5.4669e-04\n",
      "Epoch 20/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 1.0272e-04 - val_loss: 8.6539e-04\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 1.0251e-04 - val_loss: 6.5746e-04\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 1.7742e-04 - val_loss: 4.0808e-04\n",
      "Epoch 23/50\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 1.3432e-04 - val_loss: 8.2462e-04\n",
      "Epoch 24/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 2.6010e-04 - val_loss: 0.0014\n",
      "Epoch 25/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 2.0344e-04 - val_loss: 5.0896e-04\n",
      "Epoch 26/50\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 9.2109e-05 - val_loss: 6.3565e-04\n",
      "Epoch 27/50\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 9.1582e-05 - val_loss: 6.7553e-04\n",
      "Epoch 28/50\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 8.1284e-05 - val_loss: 4.4879e-04\n",
      "Epoch 29/50\n",
      "22/22 [==============================] - 1s 43ms/step - loss: 1.2003e-04 - val_loss: 0.0034\n",
      "Epoch 30/50\n",
      "22/22 [==============================] - 1s 42ms/step - loss: 1.1394e-04 - val_loss: 5.7863e-04\n",
      "Epoch 31/50\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 6.1709e-05 - val_loss: 7.4498e-04\n",
      "Epoch 32/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 7.5209e-05 - val_loss: 0.0012\n",
      "Epoch 33/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 6.1844e-05 - val_loss: 0.0015\n",
      "Epoch 34/50\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 9.6371e-05 - val_loss: 0.0032\n",
      "Epoch 35/50\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 1.1295e-04 - val_loss: 0.0014\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 6.6724e-05 - val_loss: 0.0017\n",
      "Epoch 37/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 5.3477e-05 - val_loss: 0.0012\n",
      "Epoch 38/50\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 8.9777e-05 - val_loss: 4.9152e-04\n",
      "Epoch 39/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 5.3793e-05 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 6.9256e-05 - val_loss: 0.0025\n",
      "Epoch 41/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 8.0713e-05 - val_loss: 0.0016\n",
      "Epoch 42/50\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 1.2708e-04 - val_loss: 0.0027\n",
      "Epoch 43/50\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 1.4839e-04 - val_loss: 7.2603e-04\n",
      "Epoch 44/50\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 1.2314e-04 - val_loss: 0.0016\n",
      "Epoch 45/50\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 9.9478e-05 - val_loss: 8.6739e-04\n",
      "Epoch 46/50\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 1.5561e-04 - val_loss: 0.0037\n",
      "Epoch 47/50\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 1.4064e-04 - val_loss: 0.0041\n",
      "Epoch 48/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 2.4417e-04 - val_loss: 0.0066\n",
      "Epoch 49/50\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 4.6926e-04 - val_loss: 0.0012\n",
      "Epoch 50/50\n",
      "22/22 [==============================] - 1s 46ms/step - loss: 1.9836e-04 - val_loss: 5.8466e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainY, epochs=50, batch_size=16, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb4355a1-526c-475e-8fd5-315f1658d245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 998ms/step\n"
     ]
    }
   ],
   "source": [
    "n_past = 16\n",
    "n_days_for_prediction=7\n",
    "prediction = model.predict(trainX[-n_days_for_prediction:]) #shape = (n, 1) where n is the n_days_for_prediction\n",
    "\n",
    "prediction\n",
    "scaled_back = scaler.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5357622-ace7-4420-b7d4-bf41ac3b6440",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'width'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdarts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[1;32m----> 2\u001b[0m rmse \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaled_back\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintersect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m mse \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mmse(trainY, scaled_back, intersect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m mae \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mmae(trainY, scaled_back, intersect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\darts\\metrics\\metrics.py:87\u001b[0m, in \u001b[0;36mmulti_ts_support.<locals>.wrapper_multi_ts_support\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_series\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     81\u001b[0m iterator \u001b[38;5;241m=\u001b[39m _build_tqdm_iterator(\n\u001b[0;32m     82\u001b[0m     iterable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mzip\u001b[39m(actual_series, pred_series),\n\u001b[0;32m     83\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m     84\u001b[0m     total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(actual_series),\n\u001b[0;32m     85\u001b[0m )\n\u001b[1;32m---> 87\u001b[0m value_list \u001b[38;5;241m=\u001b[39m \u001b[43m_parallel_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43miterator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnum_series_in_args\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# in case the reduction is not reducing the metrics sequence to a single value, e.g., if returning the\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# np.ndarray of values with the identity function, we must handle the single TS case, where we should\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# return a single value instead of a np.array of len 1\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\darts\\utils\\utils.py:292\u001b[0m, in \u001b[0;36m_parallel_apply\u001b[1;34m(iterator, fn, n_jobs, fn_args, fn_kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parallel_apply\u001b[39m(\n\u001b[0;32m    268\u001b[0m     iterator: Iterator[Tuple], fn: Callable, n_jobs: \u001b[38;5;28mint\u001b[39m, fn_args, fn_kwargs\n\u001b[0;32m    269\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Utility function that parallelise the execution of a function over an Iterator\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    289\u001b[0m \n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 292\u001b[0m     returned_data \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m returned_data\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\darts\\metrics\\metrics.py:125\u001b[0m, in \u001b[0;36mmultivariate_support.<locals>.wrapper_multivariate_support\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m actual_series \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    122\u001b[0m pred_series \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    124\u001b[0m raise_if_not(\n\u001b[1;32m--> 125\u001b[0m     \u001b[43mactual_series\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m \u001b[38;5;241m==\u001b[39m pred_series\u001b[38;5;241m.\u001b[39mwidth,\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe two TimeSeries instances must have the same width.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    127\u001b[0m     logger,\n\u001b[0;32m    128\u001b[0m )\n\u001b[0;32m    130\u001b[0m value_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(actual_series\u001b[38;5;241m.\u001b[39mwidth):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'width'"
     ]
    }
   ],
   "source": [
    "from darts import metrics\n",
    "rmse = metrics.metrics.rmse(trainY, scaled_back, intersect=True)\n",
    "mse = metrics.metrics.mse(trainY, scaled_back, intersect=True)\n",
    "mae = metrics.metrics.mae(trainY, scaled_back, intersect=True)\n",
    "mape = metrics.metrics.mape(trainY, scaled_back, intersect=True)\n",
    "r2 = metrics.metrics.r2_score(trainY, scaled_back, intersect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "183721fa-7cc2-444a-89e5-5862c13beb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405.38217, 296.83423, 360.03958, 321.04306, 446.46783],\n",
       "       [407.9328 , 298.4048 , 362.3515 , 323.03   , 449.8079 ],\n",
       "       [410.21848, 299.8098 , 364.42358, 324.8087 , 452.81314],\n",
       "       [412.41595, 301.1509 , 366.39273, 326.499  , 455.65295],\n",
       "       [415.02545, 302.73615, 368.7003 , 328.4837 , 458.95197],\n",
       "       [417.67142, 304.33508, 370.99933, 330.46262, 462.18344],\n",
       "       [421.4104 , 306.59103, 374.22644, 333.246  , 466.6886 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f049b5f-edcd-4a9f-aab6-c96c1cd6d3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01545016],\n",
       "       [0.01610761],\n",
       "       [0.01643634],\n",
       "       [0.01610761],\n",
       "       [0.01643634],\n",
       "       [0.01742252],\n",
       "       [0.01775125],\n",
       "       [0.01742252],\n",
       "       [0.01775125],\n",
       "       [0.01742252],\n",
       "       [0.01807997],\n",
       "       [0.01873743],\n",
       "       [0.02235342],\n",
       "       [0.02268215],\n",
       "       [0.02268215],\n",
       "       [0.02268215],\n",
       "       [0.02366833],\n",
       "       [0.02399705],\n",
       "       [0.02399705],\n",
       "       [0.02399705],\n",
       "       [0.02399705],\n",
       "       [0.02531196],\n",
       "       [0.02958541],\n",
       "       [0.02925668],\n",
       "       [0.03024286],\n",
       "       [0.03254395],\n",
       "       [0.03122904],\n",
       "       [0.03254395],\n",
       "       [0.0332014 ],\n",
       "       [0.0332014 ],\n",
       "       [0.03615995],\n",
       "       [0.04043339],\n",
       "       [0.03813231],\n",
       "       [0.03878976],\n",
       "       [0.04273448],\n",
       "       [0.04339193],\n",
       "       [0.04437811],\n",
       "       [0.04700793],\n",
       "       [0.0453643 ],\n",
       "       [0.04635048],\n",
       "       [0.04733666],\n",
       "       [0.04799411],\n",
       "       [0.04799411],\n",
       "       [0.04865156],\n",
       "       [0.04865156],\n",
       "       [0.04898029],\n",
       "       [0.05456864],\n",
       "       [0.05588355],\n",
       "       [0.05752719],\n",
       "       [0.05851337],\n",
       "       [0.05949955],\n",
       "       [0.06180063],\n",
       "       [0.06377299],\n",
       "       [0.06344427],\n",
       "       [0.06443045],\n",
       "       [0.06410172],\n",
       "       [0.06541663],\n",
       "       [0.06541663],\n",
       "       [0.06837517],\n",
       "       [0.06804644],\n",
       "       [0.06969008],\n",
       "       [0.07166244],\n",
       "       [0.07199116],\n",
       "       [0.07166244],\n",
       "       [0.07297734],\n",
       "       [0.07199116],\n",
       "       [0.0736348 ],\n",
       "       [0.0736348 ],\n",
       "       [0.07429225],\n",
       "       [0.07429225],\n",
       "       [0.07725079],\n",
       "       [0.07659334],\n",
       "       [0.07790825],\n",
       "       [0.07988061],\n",
       "       [0.08119551],\n",
       "       [0.08185297],\n",
       "       [0.08218169],\n",
       "       [0.08185297],\n",
       "       [0.08185297],\n",
       "       [0.08218169],\n",
       "       [0.08218169],\n",
       "       [0.08316787],\n",
       "       [0.0871126 ],\n",
       "       [0.08908496],\n",
       "       [0.09039986],\n",
       "       [0.09434458],\n",
       "       [0.09565949],\n",
       "       [0.09730313],\n",
       "       [0.09828931],\n",
       "       [0.09828931],\n",
       "       [0.09828931],\n",
       "       [0.09861803],\n",
       "       [0.09861803],\n",
       "       [0.10026167],\n",
       "       [0.10387766],\n",
       "       [0.10552129],\n",
       "       [0.10617875],\n",
       "       [0.10782238],\n",
       "       [0.10815111],\n",
       "       [0.11012347],\n",
       "       [0.11143838],\n",
       "       [0.11209583],\n",
       "       [0.11341074],\n",
       "       [0.11373946],\n",
       "       [0.11505437],\n",
       "       [0.11505437],\n",
       "       [0.11899909],\n",
       "       [0.12130018],\n",
       "       [0.12360127],\n",
       "       [0.12820344],\n",
       "       [0.13116198],\n",
       "       [0.13149071],\n",
       "       [0.13214816],\n",
       "       [0.13280562],\n",
       "       [0.1337918 ],\n",
       "       [0.1337918 ],\n",
       "       [0.13346307],\n",
       "       [0.13313434],\n",
       "       [0.13905143],\n",
       "       [0.14332487],\n",
       "       [0.14463978],\n",
       "       [0.14694087],\n",
       "       [0.1485845 ],\n",
       "       [0.14957068],\n",
       "       [0.15055686],\n",
       "       [0.15154304],\n",
       "       [0.15121432],\n",
       "       [0.15121432],\n",
       "       [0.15055686],\n",
       "       [0.15121432],\n",
       "       [0.15581649],\n",
       "       [0.15877503],\n",
       "       [0.16008994],\n",
       "       [0.16140485],\n",
       "       [0.16271975],\n",
       "       [0.16304848],\n",
       "       [0.16403466],\n",
       "       [0.16370593],\n",
       "       [0.16436339],\n",
       "       [0.16370593],\n",
       "       [0.16337721],\n",
       "       [0.16534957],\n",
       "       [0.16830811],\n",
       "       [0.17093792],\n",
       "       [0.17126665],\n",
       "       [0.17422519],\n",
       "       [0.17521137],\n",
       "       [0.17619755],\n",
       "       [0.17619755],\n",
       "       [0.17652628],\n",
       "       [0.17849864],\n",
       "       [0.17915609],\n",
       "       [0.17948482],\n",
       "       [0.17882737],\n",
       "       [0.1854019 ],\n",
       "       [0.18671681],\n",
       "       [0.18836044],\n",
       "       [0.19296262],\n",
       "       [0.1939488 ],\n",
       "       [0.19592116],\n",
       "       [0.19920843],\n",
       "       [0.19953715],\n",
       "       [0.20085206],\n",
       "       [0.20150951],\n",
       "       [0.20282442],\n",
       "       [0.20413933],\n",
       "       [0.22024694],\n",
       "       [0.22353421],\n",
       "       [0.22419166],\n",
       "       [0.23043747],\n",
       "       [0.23339601],\n",
       "       [0.23701201],\n",
       "       [0.23997055],\n",
       "       [0.24161418],\n",
       "       [0.24523017],\n",
       "       [0.24588763],\n",
       "       [0.25016108],\n",
       "       [0.25114726],\n",
       "       [0.27284322],\n",
       "       [0.27678794],\n",
       "       [0.28073267],\n",
       "       [0.2873072 ],\n",
       "       [0.29125192],\n",
       "       [0.29322428],\n",
       "       [0.30374354],\n",
       "       [0.30703081],\n",
       "       [0.30900317],\n",
       "       [0.30966062],\n",
       "       [0.31229044],\n",
       "       [0.31229044],\n",
       "       [0.33727367],\n",
       "       [0.34154712],\n",
       "       [0.34614929],\n",
       "       [0.35338128],\n",
       "       [0.35403874],\n",
       "       [0.35140892],\n",
       "       [0.35502492],\n",
       "       [0.36357181],\n",
       "       [0.36554417],\n",
       "       [0.37146126],\n",
       "       [0.37409107],\n",
       "       [0.37277616],\n",
       "       [0.3878976 ],\n",
       "       [0.39217104],\n",
       "       [0.3941434 ],\n",
       "       [0.39907431],\n",
       "       [0.40203285],\n",
       "       [0.40301903],\n",
       "       [0.41057974],\n",
       "       [0.41715428],\n",
       "       [0.41846919],\n",
       "       [0.41978409],\n",
       "       [0.42274263],\n",
       "       [0.42471499],\n",
       "       [0.43687788],\n",
       "       [0.43983643],\n",
       "       [0.44476733],\n",
       "       [0.45068441],\n",
       "       [0.44969823],\n",
       "       [0.44838332],\n",
       "       [0.44739714],\n",
       "       [0.44542478],\n",
       "       [0.44805459],\n",
       "       [0.44049388],\n",
       "       [0.44279497],\n",
       "       [0.44673969],\n",
       "       [0.44871205],\n",
       "       [0.45002696],\n",
       "       [0.4493695 ],\n",
       "       [0.45134186],\n",
       "       [0.45495786],\n",
       "       [0.45331422],\n",
       "       [0.45495786],\n",
       "       [0.46416221],\n",
       "       [0.45923131],\n",
       "       [0.45890258],\n",
       "       [0.45758767],\n",
       "       [0.46120367],\n",
       "       [0.46679202],\n",
       "       [0.46383348],\n",
       "       [0.46383348],\n",
       "       [0.46646329],\n",
       "       [0.46810693],\n",
       "       [0.4727091 ],\n",
       "       [0.47435274],\n",
       "       [0.47238038],\n",
       "       [0.47238038],\n",
       "       [0.46975056],\n",
       "       [0.47073674],\n",
       "       [0.4727091 ],\n",
       "       [0.4763251 ],\n",
       "       [0.48158473],\n",
       "       [0.48881672],\n",
       "       [0.49078908],\n",
       "       [0.48815926],\n",
       "       [0.48914544],\n",
       "       [0.49637743],\n",
       "       [0.49571998],\n",
       "       [0.49243271],\n",
       "       [0.49440507],\n",
       "       [0.49276144],\n",
       "       [0.49374762],\n",
       "       [0.49999343],\n",
       "       [0.50229451],\n",
       "       [0.50656796],\n",
       "       [0.50163706],\n",
       "       [0.51051268],\n",
       "       [0.50755414],\n",
       "       [0.50656796],\n",
       "       [0.50985523],\n",
       "       [0.51938831],\n",
       "       [0.51708722],\n",
       "       [0.51708722],\n",
       "       [0.52070321],\n",
       "       [0.53089374],\n",
       "       [0.53615337],\n",
       "       [0.53483846],\n",
       "       [0.54075555],\n",
       "       [0.54568645],\n",
       "       [0.54765881],\n",
       "       [0.54798753],\n",
       "       [0.54733008],\n",
       "       [0.54765881],\n",
       "       [0.54930244],\n",
       "       [0.5512748 ],\n",
       "       [0.5512748 ],\n",
       "       [0.56376642],\n",
       "       [0.56672496],\n",
       "       [0.57034096],\n",
       "       [0.57428568],\n",
       "       [0.57724422],\n",
       "       [0.57658676],\n",
       "       [0.58053149],\n",
       "       [0.58447621],\n",
       "       [0.5880922 ],\n",
       "       [0.58677729],\n",
       "       [0.58480493],\n",
       "       [0.59532419],\n",
       "       [0.61044562],\n",
       "       [0.61406162],\n",
       "       [0.61603398],\n",
       "       [0.6199787 ],\n",
       "       [0.62786814],\n",
       "       [0.62655323],\n",
       "       [0.62885432],\n",
       "       [0.6298405 ],\n",
       "       [0.62129361],\n",
       "       [0.62030743],\n",
       "       [0.61767761],\n",
       "       [0.61866379],\n",
       "       [0.64430448],\n",
       "       [0.64627684],\n",
       "       [0.64693429],\n",
       "       [0.65120774],\n",
       "       [0.65548119],\n",
       "       [0.65909718],\n",
       "       [0.65942591],\n",
       "       [0.66205573],\n",
       "       [0.66337063],\n",
       "       [0.66238445],\n",
       "       [0.65745355],\n",
       "       [0.66205573],\n",
       "       [0.6752048 ],\n",
       "       [0.68243679],\n",
       "       [0.68408042],\n",
       "       [0.68934005],\n",
       "       [0.69032623],\n",
       "       [0.69690076],\n",
       "       [0.6985444 ],\n",
       "       [0.69657204],\n",
       "       [0.69722949],\n",
       "       [0.70511893],\n",
       "       [0.70446148],\n",
       "       [0.70281785],\n",
       "       [0.72648617],\n",
       "       [0.72385636],\n",
       "       [0.72418509],\n",
       "       [0.73240326],\n",
       "       [0.73503307],\n",
       "       [0.74686723],\n",
       "       [0.75245559],\n",
       "       [0.74325124],\n",
       "       [0.74588105],\n",
       "       [0.74851087],\n",
       "       [0.74588105],\n",
       "       [0.74982577],\n",
       "       [0.77415156],\n",
       "       [0.77908246],\n",
       "       [0.78368463],\n",
       "       [0.78828681],\n",
       "       [0.79025917],\n",
       "       [0.79453262],\n",
       "       [0.79650498],\n",
       "       [0.79814861],\n",
       "       [0.79716243],\n",
       "       [0.79288898],\n",
       "       [0.7968337 ],\n",
       "       [0.79979224],\n",
       "       [0.81557113],\n",
       "       [0.82181694],\n",
       "       [0.82773402],\n",
       "       [0.82609039],\n",
       "       [0.838582  ],\n",
       "       [0.84285545],\n",
       "       [0.84566278],\n",
       "       [0.84795729],\n",
       "       [0.84894347],\n",
       "       [0.84792442],\n",
       "       [0.85168505],\n",
       "       [0.84877253],\n",
       "       [0.8998238 ],\n",
       "       [0.91406096],\n",
       "       [0.92489251],\n",
       "       [0.93420534],\n",
       "       [0.94424136],\n",
       "       [0.97743948],\n",
       "       [0.98704817],\n",
       "       [0.99479954],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Material_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f098772-1955-466d-91fd-652f458a1ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
